{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83924326-6bfc-4bc5-8c10-79abd34632e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "652bc256-51d9-4d1f-ad42-04ae55bbe364",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The main differences between Cell 2 and Cell 3 are:\n",
    "\n",
    "Pipeline Type\n",
    "\n",
    "Cell 2: Standard PySpark code for batch ETL. It reads, transforms, and writes data directly using Spark DataFrame APIs and Delta Lake.\n",
    "Cell 3: Lakeflow Declarative Pipelines (DLT) code. It uses the @dlt.table decorator to declaratively define a materialized view in a Lakeflow pipeline, which Databricks manages and keeps up to date automatically.\n",
    "Execution & Management\n",
    "\n",
    "Cell 2: Runs as a one-off job or notebook cell. You must manually rerun the code to refresh data.\n",
    "Cell 3: Runs as part of a Lakeflow Declarative Pipeline. The pipeline orchestrates updates, incremental refreshes, and lineage tracking automatically.\n",
    "Data Quality & Metadata\n",
    "\n",
    "Cell 2: No built-in support for data quality constraints or table metadata.\n",
    "Cell 3: Supports table metadata (name, comment) and can easily add data quality expectations using decorators like @dlt.expect.\n",
    "Publishing & Catalog Integration\n",
    "\n",
    "Cell 2: Writes to a Delta path, but does not automatically register the table in the metastore/catalog.\n",
    "Cell 3: Publishes the table to the catalog/schema defined in the pipeline settings, making it discoverable and queryable as a managed table.\n",
    "Incremental & Declarative Updates\n",
    "\n",
    "Cell 2: Overwrites the data each time; not incremental.\n",
    "Cell 3: Materialized view is incrementally refreshed by Databricks, optimizing for cost and performance.\n",
    "Summary:\n",
    "Cell 2 is imperative, batch ETL code. Cell 3 is declarative, pipeline-managed code that creates a materialized view with automatic refresh, catalog integration, and optional data quality constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af72a95e-cd84-406a-9d6a-d8e67ee7e1cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Process sales_customers\n",
    "\n",
    "df_customers = spark.table(\"samples.bakehouse.sales_customers\")\n",
    "\n",
    "df_customers_staging = (\n",
    "    df_customers\n",
    "    .dropDuplicates([\"customerID\"])\n",
    "    .withColumn(\"phone_number\", F.regexp_replace(\"phone_number\", \"[^0-9]\", \"\"))\n",
    "    .withColumn(\"email_address\", F.lower(F.col(\"email_address\")))\n",
    "    .withColumn(\"load_date\", F.current_timestamp())\n",
    ")\n",
    "df_customers_staging.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/staging/sales_customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "646829eb-4017-4735-8689-8c6a811ef611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"sales_customers_staging\",\n",
    "    comment=\"Processed sales_customers with cleaned phone and email\"\n",
    ")\n",
    "def sales_customers_staging():\n",
    "    df_customers = spark.read.table(\"samples.bakehouse.sales_customers\")\n",
    "    return (\n",
    "        df_customers\n",
    "        .dropDuplicates([\"customerID\"])\n",
    "        .withColumn(\"phone_number\", F.regexp_replace(\"phone_number\", \"[^0-9]\", \"\"))\n",
    "        .withColumn(\"email_address\", F.lower(F.col(\"email_address\")))\n",
    "        .withColumn(\"load_date\", F.current_timestamp())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7ef0ed4-ea6f-4868-842b-416ac5a855af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Process sales_franchises\n",
    "df_franchises = spark.table(\"samples.bakehouse.sales_franchises\")\n",
    "\n",
    "df_franchises_staging = df_franchises.withColumn(\"load_date\", F.current_timestamp())\n",
    "\n",
    "df_franchises_staging.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/staging/sales_franchises\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc781a29-21a1-42c3-a8ef-b981594158e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Process sales_suppliers\n",
    "df_suppliers = spark.table(\"samples.bakehouse.sales_suppliers\")\n",
    "\n",
    "df_suppliers_staging = (\n",
    "    df_suppliers\n",
    "    .withColumn(\"alergy\", \n",
    "                F.when(\n",
    "                    F.lower(F.col(\"ingredient\")).rlike(\"pistachios|peanuts|poppy seeds\"), \"Y\"\n",
    "                ).otherwise(\"N\")\n",
    "               )\n",
    "    .withColumn(\"load_date\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "df_suppliers_staging.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/staging/sales_suppliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42d2ffc1-f211-4447-8419-e0e238b90d85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Process sales_transactions\n",
    "df_transactions = spark.table(\"samples.bakehouse.sales_transactions\")\n",
    "\n",
    "df_transactions_staging = df_transactions.withColumn(\"load_date\", F.current_timestamp())\n",
    "\n",
    "df_transactions_staging.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/staging/sales_transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef135c99-8c84-4528-aace-c270ff84e009",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Process media_customer_reviews\n",
    "df_reviews = spark.table(\"samples.bakehouse.media_customer_reviews\")\n",
    "\n",
    "df_reviews_staging = df_reviews.withColumn(\"load_date\", F.current_timestamp())\n",
    "\n",
    "df_reviews_staging.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/staging/media_customer_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc99a467-b840-4c0e-8610-144dae063a30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Process media_gold_reviews_chunked\n",
    "df_gold_reviews = spark.table(\"samples.bakehouse.media_gold_reviews_chunked\")\n",
    "\n",
    "df_gold_reviews_staging = df_gold_reviews.withColumn(\"load_date\", F.current_timestamp())\n",
    "\n",
    "df_gold_reviews_staging.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/staging/media_gold_reviews_chunked\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Staging",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
